{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1086b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib as fl\n",
    "import os as os\n",
    "from PIL import Image\n",
    "\n",
    "labs = pd.read_csv('labels.csv')\n",
    "routes = pd.read_csv('routes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aaba4c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = labs.drop(labels = ['Unnamed: 0'], axis = 1)\n",
    "routes = routes.drop(labels = ['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d3fd7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "routes['dup'] = routes.duplicated(subset = ['1x0', '1x1', '1x2', '1x3', '1x4', '1x5', '1x6', '1x7', '1x8', '1x9', '1x10', '2x0', '2x1', '2x2', '2x3', '2x4', '2x5', '2x6', '2x7', '2x8', '2x9', '2x10', '3x0', '3x1', '3x2', '3x3', '3x4', '3x5', '3x6', '3x7', '3x8', '3x9', '3x10', '4x0', '4x1', '4x2', '4x3', '4x4', '4x5', '4x6', '4x7', '4x8', '4x9', '4x10', '5x0', '5x1', '5x2', '5x3', '5x4', '5x5', '5x6', '5x7', '5x8', '5x9', '5x10', '6x0', '6x1', '6x2', '6x3', '6x4', '6x5', '6x6', '6x7', '6x8', '6x9', '6x10', '7x0', '7x1', '7x2', '7x3', '7x4', '7x5', '7x6', '7x7', '7x8', '7x9', '7x10', '8x0', '8x1', '8x2', '8x3', '8x4', '8x5', '8x6', '8x7', '8x8', '8x9', '8x10', '9x0', '9x1', '9x2', '9x3', '9x4', '9x5', '9x6', '9x7', '9x8', '9x9', '9x10', '10x0', '10x1', '10x2', '10x3', '10x4', '10x5', '10x6', '10x7', '10x8', '10x9', '10x10', '11x0', '11x1', '11x2', '11x3', '11x4', '11x5', '11x6', '11x7', '11x8', '11x9', '11x10', '12x0', '12x1', '12x2', '12x3', '12x4', '12x5', '12x6', '12x7', '12x8', '12x9', '12x10', '13x0', '13x1', '13x2', '13x3', '13x4', '13x5', '13x6', '13x7', '13x8', '13x9', '13x10', '14x0', '14x1', '14x2', '14x3', '14x4', '14x5', '14x6', '14x7', '14x8', '14x9', '14x10', '15x0', '15x1', '15x2', '15x3', '15x4', '15x5', '15x6', '15x7', '15x8', '15x9', '15x10', '16x0', '16x1', '16x2', '16x3', '16x4', '16x5', '16x6', '16x7', '16x8', '16x9', '16x10', '17x0', '17x1', '17x2', '17x3', '17x4', '17x5', '17x6', '17x7', '17x8', '17x9', '17x10', '18x0', '18x1', '18x2', '18x3', '18x4', '18x5', '18x6', '18x7', '18x8', '18x9', '18x10'], keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a57624e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x0</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>18x2</th>\n",
       "      <th>18x3</th>\n",
       "      <th>18x4</th>\n",
       "      <th>18x5</th>\n",
       "      <th>18x6</th>\n",
       "      <th>18x7</th>\n",
       "      <th>18x8</th>\n",
       "      <th>18x9</th>\n",
       "      <th>18x10</th>\n",
       "      <th>dup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th># E-Z WARMUP</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>##1</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>##2</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>##3</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>##4</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZZ BY E.</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZZZZZZZZZZ</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>] V5-6</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_TEST1</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>â€œSKY AND SAND â€œ</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29752 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    1x0 1x1 1x2 1x3 1x4 1x5 1x6 1x7 1x8 1x9  ... 18x2 18x3  \\\n",
       "Name                                                         ...             \n",
       "# E-Z WARMUP          N   N   N   N   N   N   N   N   N   N  ...    N    N   \n",
       "##1                   N   N   N   N   N   N   N   N   N   N  ...    N    N   \n",
       "##2                   N   N   N   N   N   N   N   N   N   N  ...    N    N   \n",
       "##3                   N   N   N   N   N   N   N   N   N   N  ...    N    N   \n",
       "##4                   N   N   N   N   N   N   N   N   N   N  ...    N    N   \n",
       "...                  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...   \n",
       "ZZZ BY E.             N   N   N   N   N   N   N   N   N   N  ...    F    N   \n",
       "ZZZZZZZZZZ            N   N   N   N   N   N   N   N   N   N  ...    N    F   \n",
       "] V5-6                N   N   N   N   N   N   N   N   N   N  ...    N    N   \n",
       "_TEST1                N   N   N   N   N   N   N   N   N   N  ...    N    N   \n",
       "â€œSKY AND SAND â€œ   N   N   N   N   N   N   N   N   N   N  ...    N    F   \n",
       "\n",
       "                    18x4 18x5 18x6 18x7 18x8 18x9 18x10    dup  \n",
       "Name                                                            \n",
       "# E-Z WARMUP           N    N    N    N    F    N     N  False  \n",
       "##1                    F    N    N    N    N    N     N  False  \n",
       "##2                    N    N    N    N    F    N     N  False  \n",
       "##3                    N    N    N    N    N    N     F  False  \n",
       "##4                    N    N    N    N    F    N     N  False  \n",
       "...                  ...  ...  ...  ...  ...  ...   ...    ...  \n",
       "ZZZ BY E.              N    N    N    N    N    N     N  False  \n",
       "ZZZZZZZZZZ             N    N    N    N    N    N     N   True  \n",
       "] V5-6                 N    N    F    N    N    N     N  False  \n",
       "_TEST1                 N    N    F    N    N    N     N  False  \n",
       "â€œSKY AND SAND â€œ    N    N    N    N    N    N     N   True  \n",
       "\n",
       "[29752 rows x 199 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes.index = routes['Name']\n",
    "routes = routes.drop(labels =['Name'], axis = 1)\n",
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd6b9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = labs.join(routes, on = 'Name',how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5e6f150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs['dup'] = labs.duplicated(subset = ['1x0', '1x1', '1x2', '1x3', '1x4', '1x5', '1x6', '1x7', '1x8', '1x9', '1x10', '2x0', '2x1', '2x2', '2x3', '2x4', '2x5', '2x6', '2x7', '2x8', '2x9', '2x10', '3x0', '3x1', '3x2', '3x3', '3x4', '3x5', '3x6', '3x7', '3x8', '3x9', '3x10', '4x0', '4x1', '4x2', '4x3', '4x4', '4x5', '4x6', '4x7', '4x8', '4x9', '4x10', '5x0', '5x1', '5x2', '5x3', '5x4', '5x5', '5x6', '5x7', '5x8', '5x9', '5x10', '6x0', '6x1', '6x2', '6x3', '6x4', '6x5', '6x6', '6x7', '6x8', '6x9', '6x10', '7x0', '7x1', '7x2', '7x3', '7x4', '7x5', '7x6', '7x7', '7x8', '7x9', '7x10', '8x0', '8x1', '8x2', '8x3', '8x4', '8x5', '8x6', '8x7', '8x8', '8x9', '8x10', '9x0', '9x1', '9x2', '9x3', '9x4', '9x5', '9x6', '9x7', '9x8', '9x9', '9x10', '10x0', '10x1', '10x2', '10x3', '10x4', '10x5', '10x6', '10x7', '10x8', '10x9', '10x10', '11x0', '11x1', '11x2', '11x3', '11x4', '11x5', '11x6', '11x7', '11x8', '11x9', '11x10', '12x0', '12x1', '12x2', '12x3', '12x4', '12x5', '12x6', '12x7', '12x8', '12x9', '12x10', '13x0', '13x1', '13x2', '13x3', '13x4', '13x5', '13x6', '13x7', '13x8', '13x9', '13x10', '14x0', '14x1', '14x2', '14x3', '14x4', '14x5', '14x6', '14x7', '14x8', '14x9', '14x10', '15x0', '15x1', '15x2', '15x3', '15x4', '15x5', '15x6', '15x7', '15x8', '15x9', '15x10', '16x0', '16x1', '16x2', '16x3', '16x4', '16x5', '16x6', '16x7', '16x8', '16x9', '16x10', '17x0', '17x1', '17x2', '17x3', '17x4', '17x5', '17x6', '17x7', '17x8', '17x9', '17x10', '18x0', '18x1', '18x2', '18x3', '18x4', '18x5', '18x6', '18x7', '18x8', '18x9', '18x10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e38d5a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut to relavent data:\n",
    "\n",
    "smaller = labs.drop(labels = ['Stars1', 'Stars2', 'Type', 'dup'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36e23828",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller = smaller.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d2c2b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller = smaller.drop_duplicates(subset = ['1x0', '1x1', '1x2', '1x3', '1x4', '1x5', '1x6', '1x7', '1x8', '1x9', '1x10', '2x0', '2x1', '2x2', '2x3', '2x4', '2x5', '2x6', '2x7', '2x8', '2x9', '2x10', '3x0', '3x1', '3x2', '3x3', '3x4', '3x5', '3x6', '3x7', '3x8', '3x9', '3x10', '4x0', '4x1', '4x2', '4x3', '4x4', '4x5', '4x6', '4x7', '4x8', '4x9', '4x10', '5x0', '5x1', '5x2', '5x3', '5x4', '5x5', '5x6', '5x7', '5x8', '5x9', '5x10', '6x0', '6x1', '6x2', '6x3', '6x4', '6x5', '6x6', '6x7', '6x8', '6x9', '6x10', '7x0', '7x1', '7x2', '7x3', '7x4', '7x5', '7x6', '7x7', '7x8', '7x9', '7x10', '8x0', '8x1', '8x2', '8x3', '8x4', '8x5', '8x6', '8x7', '8x8', '8x9', '8x10', '9x0', '9x1', '9x2', '9x3', '9x4', '9x5', '9x6', '9x7', '9x8', '9x9', '9x10', '10x0', '10x1', '10x2', '10x3', '10x4', '10x5', '10x6', '10x7', '10x8', '10x9', '10x10', '11x0', '11x1', '11x2', '11x3', '11x4', '11x5', '11x6', '11x7', '11x8', '11x9', '11x10', '12x0', '12x1', '12x2', '12x3', '12x4', '12x5', '12x6', '12x7', '12x8', '12x9', '12x10', '13x0', '13x1', '13x2', '13x3', '13x4', '13x5', '13x6', '13x7', '13x8', '13x9', '13x10', '14x0', '14x1', '14x2', '14x3', '14x4', '14x5', '14x6', '14x7', '14x8', '14x9', '14x10', '15x0', '15x1', '15x2', '15x3', '15x4', '15x5', '15x6', '15x7', '15x8', '15x9', '15x10', '16x0', '16x1', '16x2', '16x3', '16x4', '16x5', '16x6', '16x7', '16x8', '16x9', '16x10', '17x0', '17x1', '17x2', '17x3', '17x4', '17x5', '17x6', '17x7', '17x8', '17x9', '17x10', '18x0', '18x1', '18x2', '18x3', '18x4', '18x5', '18x6', '18x7', '18x8', '18x9', '18x10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "da6dad71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              20928 repeats\n",
       "1                              29496 repeats\n",
       "2                                612 repeats\n",
       "3                               7494 repeats\n",
       "4                                221 repeats\n",
       "                        ...                 \n",
       "34788                              3 repeats\n",
       "34789    1 climber has repeated this problem\n",
       "34791    1 climber has repeated this problem\n",
       "34792                               4repeats\n",
       "34794                             25 repeats\n",
       "Name: Repeats, Length: 18943, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller = smaller[smaller['Repeats'] != 'Be the first to repeat this problem'] # drop low repeats\n",
    "smaller['Repeats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "06c38bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = smaller['Repeats'].values\n",
    "\n",
    "for i in range(len(vals)):\n",
    "    vals[i] = vals[i].rstrip('repeats')\n",
    "    vals[i] = vals[i].rstrip('climber has repeated this problem')\n",
    "    vals[i] = vals[i].replace('S','5')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436455de",
   "metadata": {},
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "36c1575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20928' '29496' '612' ... '1' '4' '25']\n"
     ]
    }
   ],
   "source": [
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2ee4f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller['Repeats'] = pd.to_numeric(smaller['Repeats'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "45c8e7a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6B+ (User grade 6B+)', '6B+ (User grade 6B+)',\n",
       "       '6B+ (User grade 6B+)', ..., '7C (User grade 7C)', '6C',\n",
       "       '6C (User grade 6C)'], dtype=object)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = smaller['Grade'].values\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "51ac5102",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(grades)):\n",
    "    grades[i] = (grades[i].split('(')[0].replace('TA+', '7A+').replace('TAt', '7a+').replace('baT','6a+').replace('++','+').strip())\n",
    "    if grades[i].isupper():\n",
    "        pass\n",
    "    else:\n",
    "        grades[i] = grades[i].swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7cc7dce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7A+'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'7a+'.swapcase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4fe0ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_grade(grade):\n",
    "    return grade in ['6B+', '7A', '7B', '7A+', '6C+', '7B+', '6C', '7C', '7C+','6B', '8A', '8B', '8A+', '8B+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a3f8ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Repeats</th>\n",
       "      <th>Grade</th>\n",
       "      <th>1x0</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>...</th>\n",
       "      <th>18x1</th>\n",
       "      <th>18x2</th>\n",
       "      <th>18x3</th>\n",
       "      <th>18x4</th>\n",
       "      <th>18x5</th>\n",
       "      <th>18x6</th>\n",
       "      <th>18x7</th>\n",
       "      <th>18x8</th>\n",
       "      <th>18x9</th>\n",
       "      <th>18x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAR FROM THE MADDING CROWD</td>\n",
       "      <td>Ben Moon</td>\n",
       "      <td>20928.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WUTHERING HEIGHTS</td>\n",
       "      <td>Ben Moon</td>\n",
       "      <td>29496.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROBLEM 3</td>\n",
       "      <td>Ally Patrick</td>\n",
       "      <td>612.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARD TIMES</td>\n",
       "      <td>Ben Moon</td>\n",
       "      <td>7494.0</td>\n",
       "      <td>7A</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROBLEM 5</td>\n",
       "      <td>Ally Patrick</td>\n",
       "      <td>221.0</td>\n",
       "      <td>7A</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>ELECTRON TOM</td>\n",
       "      <td>MTikusis</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>ATTIK</td>\n",
       "      <td>MTikusis</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>CORE CLIMBERS</td>\n",
       "      <td>Ivan Luo</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34792</th>\n",
       "      <td>FOR THE TALL AND OLD 1</td>\n",
       "      <td>martin nygren</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34794</th>\n",
       "      <td>AIRPLANES</td>\n",
       "      <td>Julia Bobak</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18943 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name        Creator  Repeats Grade 1x0 1x1 1x2  \\\n",
       "0      FAR FROM THE MADDING CROWD       Ben Moon  20928.0   6B+   N   N   N   \n",
       "1               WUTHERING HEIGHTS       Ben Moon  29496.0   6B+   N   N   N   \n",
       "2                       PROBLEM 3   Ally Patrick    612.0   6B+   N   N   N   \n",
       "3                      HARD TIMES       Ben Moon   7494.0    7A   N   N   N   \n",
       "4                       PROBLEM 5   Ally Patrick    221.0    7A   N   N   N   \n",
       "...                           ...            ...      ...   ...  ..  ..  ..   \n",
       "34788                ELECTRON TOM       MTikusis      3.0    6C   N   N   N   \n",
       "34789                       ATTIK       MTikusis      1.0   6B+   N   N   N   \n",
       "34791               CORE CLIMBERS       Ivan Luo      1.0    7C   N   N   N   \n",
       "34792      FOR THE TALL AND OLD 1  martin nygren      4.0    6C   N   N   N   \n",
       "34794                   AIRPLANES    Julia Bobak     25.0    6C   N   N   N   \n",
       "\n",
       "      1x3 1x4 1x5  ... 18x1 18x2 18x3 18x4 18x5 18x6 18x7 18x8 18x9 18x10  \n",
       "0       N   N   N  ...    N    N    F    N    N    N    N    N    N     N  \n",
       "1       N   N   N  ...    N    N    N    F    N    N    N    N    N     N  \n",
       "2       N   N   N  ...    N    N    N    N    N    N    N    F    N     N  \n",
       "3       N   N   N  ...    N    N    N    N    N    N    N    F    N     N  \n",
       "4       N   N   N  ...    N    N    F    N    N    N    N    N    N     N  \n",
       "...    ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  \n",
       "34788   N   N   N  ...    N    N    F    N    N    N    N    N    N     N  \n",
       "34789   N   N   N  ...    N    N    N    N    N    F    N    N    N     N  \n",
       "34791   N   N   N  ...    N    N    N    N    N    N    N    N    N     F  \n",
       "34792   N   N   N  ...    N    N    N    N    N    F    N    N    N     N  \n",
       "34794   N   N   N  ...    F    N    N    N    N    N    N    N    N     N  \n",
       "\n",
       "[18943 rows x 202 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0f624684",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller = smaller[smaller['Repeats'] > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "af7d1d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Creator</th>\n",
       "      <th>Repeats</th>\n",
       "      <th>Grade</th>\n",
       "      <th>1x0</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>...</th>\n",
       "      <th>18x1</th>\n",
       "      <th>18x2</th>\n",
       "      <th>18x3</th>\n",
       "      <th>18x4</th>\n",
       "      <th>18x5</th>\n",
       "      <th>18x6</th>\n",
       "      <th>18x7</th>\n",
       "      <th>18x8</th>\n",
       "      <th>18x9</th>\n",
       "      <th>18x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FAR FROM THE MADDING CROWD</td>\n",
       "      <td>Ben Moon</td>\n",
       "      <td>20928.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WUTHERING HEIGHTS</td>\n",
       "      <td>Ben Moon</td>\n",
       "      <td>29496.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROBLEM 3</td>\n",
       "      <td>Ally Patrick</td>\n",
       "      <td>612.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARD TIMES</td>\n",
       "      <td>Ben Moon</td>\n",
       "      <td>7494.0</td>\n",
       "      <td>7A</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROBLEM 5</td>\n",
       "      <td>Ally Patrick</td>\n",
       "      <td>221.0</td>\n",
       "      <td>7A</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34774</th>\n",
       "      <td>TI VOLEVO BENE</td>\n",
       "      <td>Piffer97</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34775</th>\n",
       "      <td>TI VOLEVO BENE VAR</td>\n",
       "      <td>Piffer97</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34779</th>\n",
       "      <td>PIG BIM</td>\n",
       "      <td>Joao Horst</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34792</th>\n",
       "      <td>FOR THE TALL AND OLD 1</td>\n",
       "      <td>martin nygren</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34794</th>\n",
       "      <td>AIRPLANES</td>\n",
       "      <td>Julia Bobak</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11803 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name        Creator  Repeats Grade 1x0 1x1 1x2  \\\n",
       "0      FAR FROM THE MADDING CROWD       Ben Moon  20928.0   6B+   N   N   N   \n",
       "1               WUTHERING HEIGHTS       Ben Moon  29496.0   6B+   N   N   N   \n",
       "2                       PROBLEM 3   Ally Patrick    612.0   6B+   N   N   N   \n",
       "3                      HARD TIMES       Ben Moon   7494.0    7A   N   N   N   \n",
       "4                       PROBLEM 5   Ally Patrick    221.0    7A   N   N   N   \n",
       "...                           ...            ...      ...   ...  ..  ..  ..   \n",
       "34774              TI VOLEVO BENE       Piffer97     17.0   6B+   N   N   N   \n",
       "34775          TI VOLEVO BENE VAR       Piffer97      6.0    6C   N   N   N   \n",
       "34779                     PIG BIM     Joao Horst     16.0   6B+   N   N   N   \n",
       "34792      FOR THE TALL AND OLD 1  martin nygren      4.0    6C   N   N   N   \n",
       "34794                   AIRPLANES    Julia Bobak     25.0    6C   N   N   N   \n",
       "\n",
       "      1x3 1x4 1x5  ... 18x1 18x2 18x3 18x4 18x5 18x6 18x7 18x8 18x9 18x10  \n",
       "0       N   N   N  ...    N    N    F    N    N    N    N    N    N     N  \n",
       "1       N   N   N  ...    N    N    N    F    N    N    N    N    N     N  \n",
       "2       N   N   N  ...    N    N    N    N    N    N    N    F    N     N  \n",
       "3       N   N   N  ...    N    N    N    N    N    N    N    F    N     N  \n",
       "4       N   N   N  ...    N    N    F    N    N    N    N    N    N     N  \n",
       "...    ..  ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  \n",
       "34774   N   N   N  ...    N    N    F    N    N    N    N    N    N     N  \n",
       "34775   N   N   N  ...    N    N    F    N    N    N    N    N    N     N  \n",
       "34779   N   N   N  ...    N    N    F    N    N    N    N    N    N     N  \n",
       "34792   N   N   N  ...    N    N    N    N    N    F    N    N    N     N  \n",
       "34794   N   N   N  ...    F    N    N    N    N    N    N    N    N     N  \n",
       "\n",
       "[11803 rows x 202 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6a071d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = smaller.drop(labels = ['Creator', 'Name'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b536cffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = ['6B+', '7A', '7B', '7A+', '6C+', '7B+', '6C', '7C', '7C+','6B', '8A', '8B', '8A+', '8B+']\n",
    "valid = []\n",
    "for grade in data['Grade']:\n",
    "    if grade in grades:\n",
    "        valid.append(True)\n",
    "    else:\n",
    "        valid.append(False)\n",
    "\n",
    "num_v = np.array(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "af614ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6B',\n",
       " '6B+',\n",
       " '6C',\n",
       " '6C+',\n",
       " '7A',\n",
       " '7A+',\n",
       " '7B',\n",
       " '7B+',\n",
       " '7C',\n",
       " '7C+',\n",
       " '8A',\n",
       " '8A+',\n",
       " '8B',\n",
       " '8B+']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades.sort()\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1bb341d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[num_v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "52814586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repeats</th>\n",
       "      <th>Grade</th>\n",
       "      <th>1x0</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>...</th>\n",
       "      <th>18x1</th>\n",
       "      <th>18x2</th>\n",
       "      <th>18x3</th>\n",
       "      <th>18x4</th>\n",
       "      <th>18x5</th>\n",
       "      <th>18x6</th>\n",
       "      <th>18x7</th>\n",
       "      <th>18x8</th>\n",
       "      <th>18x9</th>\n",
       "      <th>18x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20928.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29496.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>612.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7494.0</td>\n",
       "      <td>7A</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221.0</td>\n",
       "      <td>7A</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34774</th>\n",
       "      <td>17.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34775</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34779</th>\n",
       "      <td>16.0</td>\n",
       "      <td>6B+</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34792</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34794</th>\n",
       "      <td>25.0</td>\n",
       "      <td>6C</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11803 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Repeats Grade 1x0 1x1 1x2 1x3 1x4 1x5 1x6 1x7  ... 18x1 18x2 18x3 18x4  \\\n",
       "0      20928.0   6B+   N   N   N   N   N   N   N   N  ...    N    N    F    N   \n",
       "1      29496.0   6B+   N   N   N   N   N   N   N   N  ...    N    N    N    F   \n",
       "2        612.0   6B+   N   N   N   N   N   N   N   N  ...    N    N    N    N   \n",
       "3       7494.0    7A   N   N   N   N   N   N   N   N  ...    N    N    N    N   \n",
       "4        221.0    7A   N   N   N   N   N   N   N   N  ...    N    N    F    N   \n",
       "...        ...   ...  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...   \n",
       "34774     17.0   6B+   N   N   N   N   N   N   N   N  ...    N    N    F    N   \n",
       "34775      6.0    6C   N   N   N   N   N   N   N   N  ...    N    N    F    N   \n",
       "34779     16.0   6B+   N   N   N   N   N   N   N   N  ...    N    N    F    N   \n",
       "34792      4.0    6C   N   N   N   N   N   N   N   N  ...    N    N    N    N   \n",
       "34794     25.0    6C   N   N   N   N   N   N   N   N  ...    F    N    N    N   \n",
       "\n",
       "      18x5 18x6 18x7 18x8 18x9 18x10  \n",
       "0        N    N    N    N    N     N  \n",
       "1        N    N    N    N    N     N  \n",
       "2        N    N    N    F    N     N  \n",
       "3        N    N    N    F    N     N  \n",
       "4        N    N    N    N    N     N  \n",
       "...    ...  ...  ...  ...  ...   ...  \n",
       "34774    N    N    N    N    N     N  \n",
       "34775    N    N    N    N    N     N  \n",
       "34779    N    N    N    N    N     N  \n",
       "34792    N    F    N    N    N     N  \n",
       "34794    N    N    N    N    N     N  \n",
       "\n",
       "[11803 rows x 200 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6aaa5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import keras\n",
    "import keras.optimizers\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Layer\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, Softmax\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.losses import Loss\n",
    "from tensorflow.keras.optimizers import SGD, Adam,RMSprop, Adadelta\n",
    "from random import randint\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d47307bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(labels = ['Grade', 'Repeats'], axis = 1)\n",
    "Y = data['Grade']\n",
    "weights = data['Repeats']\n",
    "#split dataset into train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e9b2f010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        6B+\n",
       "1        6B+\n",
       "2        6B+\n",
       "3         7A\n",
       "4         7A\n",
       "        ... \n",
       "34774    6B+\n",
       "34775     6C\n",
       "34779    6B+\n",
       "34792     6C\n",
       "34794     6C\n",
       "Name: Grade, Length: 11803, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4befd2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        145.0\n",
       "1        172.0\n",
       "2         25.0\n",
       "3         87.0\n",
       "4         15.0\n",
       "         ...  \n",
       "34774      5.0\n",
       "34775      3.0\n",
       "34779      4.0\n",
       "34792      2.0\n",
       "34794      5.0\n",
       "Name: Repeats, Length: 11803, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.sqrt(weights)\n",
    "weights = np.ceil(weights)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "345f33e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x0</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>18x1</th>\n",
       "      <th>18x2</th>\n",
       "      <th>18x3</th>\n",
       "      <th>18x4</th>\n",
       "      <th>18x5</th>\n",
       "      <th>18x6</th>\n",
       "      <th>18x7</th>\n",
       "      <th>18x8</th>\n",
       "      <th>18x9</th>\n",
       "      <th>18x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34774</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34775</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34779</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34792</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34794</th>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11803 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1x0 1x1 1x2 1x3 1x4 1x5 1x6 1x7 1x8 1x9  ... 18x1 18x2 18x3 18x4 18x5  \\\n",
       "0       N   N   N   N   N   N   N   N   N   N  ...    N    N    F    N    N   \n",
       "1       N   N   N   N   N   N   N   N   N   N  ...    N    N    N    F    N   \n",
       "2       N   N   N   N   N   N   N   N   N   N  ...    N    N    N    N    N   \n",
       "3       N   N   N   N   N   N   N   N   N   N  ...    N    N    N    N    N   \n",
       "4       N   N   N   N   N   N   N   N   N   N  ...    N    N    F    N    N   \n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
       "34774   N   N   N   N   N   N   N   N   N   N  ...    N    N    F    N    N   \n",
       "34775   N   N   N   N   N   N   N   N   N   N  ...    N    N    F    N    N   \n",
       "34779   N   N   N   N   N   N   N   N   N   N  ...    N    N    F    N    N   \n",
       "34792   N   N   N   N   N   N   N   N   N   N  ...    N    N    N    N    N   \n",
       "34794   N   N   N   N   N   N   N   N   N   N  ...    F    N    N    N    N   \n",
       "\n",
       "      18x6 18x7 18x8 18x9 18x10  \n",
       "0        N    N    N    N     N  \n",
       "1        N    N    N    N     N  \n",
       "2        N    N    F    N     N  \n",
       "3        N    N    F    N     N  \n",
       "4        N    N    N    N     N  \n",
       "...    ...  ...  ...  ...   ...  \n",
       "34774    N    N    N    N     N  \n",
       "34775    N    N    N    N     N  \n",
       "34779    N    N    N    N     N  \n",
       "34792    F    N    N    N     N  \n",
       "34794    N    N    N    N     N  \n",
       "\n",
       "[11803 rows x 198 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "59c6524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_arr = []\n",
    "for i in range(len(grades)):\n",
    "    rep_arr.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "396e4e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        4\n",
       "4        4\n",
       "        ..\n",
       "34774    1\n",
       "34775    2\n",
       "34779    1\n",
       "34792    2\n",
       "34794    2\n",
       "Name: Grade, Length: 11803, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.replace(grades, rep_arr, inplace = True)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8d0c1cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  4,  6,  5,  3,  7,  2,  8,  9,  0, 10, 12, 11, 13],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d04c8071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6B',\n",
       " '6B+',\n",
       " '6C',\n",
       " '6C+',\n",
       " '7A',\n",
       " '7A+',\n",
       " '7B',\n",
       " '7B+',\n",
       " '7C',\n",
       " '7C+',\n",
       " '8A',\n",
       " '8A+',\n",
       " '8B',\n",
       " '8B+']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53b69df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c7b58320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert X to numeric:\n",
    "\n",
    "for col in X:\n",
    "    X[col].replace(['N','U','S','F'], [0,1,1,1], inplace = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6a64374e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1x0</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>18x1</th>\n",
       "      <th>18x2</th>\n",
       "      <th>18x3</th>\n",
       "      <th>18x4</th>\n",
       "      <th>18x5</th>\n",
       "      <th>18x6</th>\n",
       "      <th>18x7</th>\n",
       "      <th>18x8</th>\n",
       "      <th>18x9</th>\n",
       "      <th>18x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34774</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34775</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34779</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34792</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34794</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11803 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1x0  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  18x1  18x2  \\\n",
       "0        0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "1        0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "2        0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "3        0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "4        0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "34774    0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "34775    0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "34779    0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "34792    0    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "34794    0    0    0    0    0    0    0    0    0    0  ...     1     0   \n",
       "\n",
       "       18x3  18x4  18x5  18x6  18x7  18x8  18x9  18x10  \n",
       "0         1     0     0     0     0     0     0      0  \n",
       "1         0     1     0     0     0     0     0      0  \n",
       "2         0     0     0     0     0     1     0      0  \n",
       "3         0     0     0     0     0     1     0      0  \n",
       "4         1     0     0     0     0     0     0      0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...    ...  \n",
       "34774     1     0     0     0     0     0     0      0  \n",
       "34775     1     0     0     0     0     0     0      0  \n",
       "34779     1     0     0     0     0     0     0      0  \n",
       "34792     0     0     0     1     0     0     0      0  \n",
       "34794     0     0     0     0     0     0     0      0  \n",
       "\n",
       "[11803 rows x 198 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a0e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "726bcb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test, w_train, w_test = train_test_split(X, Y, weights, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d79b2",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "I don't love the loss functions that tensorflow comes with on its own. So I'm going to create my own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d034547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeLoss(Loss):\n",
    "\n",
    "  def call(self, y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32) # Some categorical number (we use one-hot encoding)\n",
    "    y_true = tf.cast(y_true, tf.int64) # Another categorical\n",
    "    cur_acc = 0\n",
    "    cur_acc = tf.cast(cur_acc, tf.float32)\n",
    "    temp = 0\n",
    "    div = tf.cast(len(y_pred), tf.float32)\n",
    "    for t in range(len(y_pred)):\n",
    "        temp = tf.math.square(tf.math.add(tf.math.abs(tf.math.subtract(tf.math.argmax(y_pred[t]), tf.math.reduce_max(y_true[t]))),1))\n",
    "        temp = tf.cast(temp, tf.float32)\n",
    "        cur_acc = tf.math.add(cur_acc, temp)\n",
    "    return tf.math.divide(cur_acc, div)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dbc34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GradeMetric(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32) # Some categorical number (we use one-hot encoding)\n",
    "    y_true = tf.cast(y_true, y_pred.dtype) # Another categorical\n",
    "    return tf.reduce_mean(tf.math.reciprocal_no_nan(tf.math.square(tf.math.add(tf.math.abs(tf.math.subtract(y_pred,y_true)),1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661d6a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b4def6",
   "metadata": {},
   "source": [
    "### Explanation for our functions. \n",
    "\n",
    "The Grade Loss is just the difference of squares function between the two numbers. I may include an offset to penalize a differnce of one more, but I think this is pretty close. \n",
    "\n",
    "Our GradeMetric is the reciprocal of the difference of squares of the grades, plus one. We take this approach instead of a traditional \"Categorized Correctly\" approach since our categories are more like discrete numbers. There is a lot of similarity in real life between a 6B and a 6B+ (in fact, we would rank them the same in America). I may fiddle with the details more later, but giving a 0.5 for being off by one grade doesn't seem too inaccurate. Maybe I'll lower than to 0.333 or 0.25, but we'll see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "89b60f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"route_grader\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 198)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                12736     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,849\n",
      "Trainable params: 14,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(198,)) # We give a 198 length vector\n",
    "\n",
    "dense = Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "x = Dense(32, activation=\"elu\")(x)\n",
    "outputs = Dense(1)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"route_grader\")\n",
    "model.summary()\n",
    "# A 198 -> 64 -> 32 -> 14 learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "08b98e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 4ms/step - loss: 2.8732 - sparse_categorical_accuracy: 0.4012 - val_loss: 2.2459 - val_sparse_categorical_accuracy: 0.4320\n",
      "Epoch 2/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.2153 - sparse_categorical_accuracy: 0.4169 - val_loss: 2.2410 - val_sparse_categorical_accuracy: 0.4367\n",
      "Epoch 3/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.1328 - sparse_categorical_accuracy: 0.4198 - val_loss: 2.1191 - val_sparse_categorical_accuracy: 0.4371\n",
      "Epoch 4/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.0478 - sparse_categorical_accuracy: 0.4231 - val_loss: 2.0114 - val_sparse_categorical_accuracy: 0.4405\n",
      "Epoch 5/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 2.0318 - sparse_categorical_accuracy: 0.4338 - val_loss: 2.0441 - val_sparse_categorical_accuracy: 0.4528\n",
      "Epoch 6/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.9708 - sparse_categorical_accuracy: 0.4352 - val_loss: 1.9814 - val_sparse_categorical_accuracy: 0.4536\n",
      "Epoch 7/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.9378 - sparse_categorical_accuracy: 0.4401 - val_loss: 1.9337 - val_sparse_categorical_accuracy: 0.4557\n",
      "Epoch 8/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.9370 - sparse_categorical_accuracy: 0.4434 - val_loss: 1.8751 - val_sparse_categorical_accuracy: 0.4655\n",
      "Epoch 9/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.9054 - sparse_categorical_accuracy: 0.4501 - val_loss: 1.8947 - val_sparse_categorical_accuracy: 0.4689\n",
      "Epoch 10/10\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 1.9046 - sparse_categorical_accuracy: 0.4477 - val_loss: 1.9296 - val_sparse_categorical_accuracy: 0.4727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "# lr - learning rate, momentum - additional parameter influencing gradient descent\n",
    "optimizer = SGD(lr=0.001, momentum = 0.9) \n",
    "#optimizer = Adadelta()\n",
    "\n",
    "inputs = keras.Input(shape=(198,)) # We give a 198 length vector\n",
    "\n",
    "dense = Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "x = Dense(32, activation=\"elu\")(x)\n",
    "outputs = Dense(14)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"route_grader\")\n",
    "\n",
    "# Compile the model, asking also to keep track of accuracy at different iterations\n",
    "model.compile(optimizer = optimizer, loss = 'SparseCategoricalCrossentropy', metrics = ['SparseCategoricalAccuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model. If you want to see the progress, set verbose=True (it is also True by default)\n",
    "history = model.fit(X_train, Y_train, epochs = epochs, verbose=True, shuffle=True,\n",
    "                    validation_data = (X_test,Y_test), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6dfa4394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cur_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"cur_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b9d8f208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 992us/step - loss: 1.9296 - sparse_categorical_accuracy: 0.4727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9295830726623535, 0.47268107533454895]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.compile(optimizer = optimizer, loss = keras.losses.SparseCategoricalCrossentropy(), metrics = [newGradeMetric])\n",
    "model.evaluate(X_test,Y_test,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f53709e7",
   "metadata": {},
   "outputs": [],
   "source": [
    " a= model.predict(X_test, batch_size = len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ce761e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36136317,  0.83159465,  0.65437347,  0.48612645,  0.63423103,\n",
       "        0.0476352 ,  0.15685758,  0.08074622, -0.24818665, -0.16889384,\n",
       "       -0.3431445 , -0.30807185, -0.4033618 , -0.2327342 ], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a26cbab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newGradeMetric(y_true, y_pred):\n",
    "    y_pred = tf.cast(y_pred, tf.float32) # Some categorical number (we use one-hot encoding)\n",
    "    y_true = tf.cast(y_true, tf.int64) # Another categorical\n",
    "    cur_acc = 0\n",
    "    cur_acc = tf.cast(cur_acc, tf.float32)\n",
    "    temp = 0\n",
    "    div = tf.cast(len(y_pred), tf.float32)\n",
    "    for t in range(len(y_pred)):\n",
    "        temp = tf.math.abs(tf.math.subtract(tf.math.argmax(y_pred[t]), tf.math.reduce_max(y_true[t])))\n",
    "        temp = tf.experimental.numpy.power(2, temp)\n",
    "        temp = tf.cast(temp, tf.float32)\n",
    "        temp = tf.math.reciprocal_no_nan(temp)\n",
    "        cur_acc = tf.math.add(cur_acc, temp)\n",
    "    return tf.math.divide(cur_acc, div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d14cc98f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6320556>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = newGradeMetric(Y_test, a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264be199",
   "metadata": {},
   "source": [
    "# Modifying the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c7f519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 3ms/step - loss: 3.5468 - sparse_categorical_accuracy: 0.1243 - val_loss: 2.7753 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 2/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.1984 - sparse_categorical_accuracy: 0.0091 - val_loss: 2.1080 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 3/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.1501 - sparse_categorical_accuracy: 0.0091 - val_loss: 2.1180 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 4/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.0962 - sparse_categorical_accuracy: 0.0091 - val_loss: 2.0478 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 5/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.0398 - sparse_categorical_accuracy: 0.0091 - val_loss: 2.0266 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 6/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.0205 - sparse_categorical_accuracy: 0.0091 - val_loss: 2.0250 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 7/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 2.0054 - sparse_categorical_accuracy: 0.0091 - val_loss: 2.0182 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 8/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9926 - sparse_categorical_accuracy: 0.0091 - val_loss: 2.0046 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 9/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9821 - sparse_categorical_accuracy: 0.0091 - val_loss: 1.9901 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 10/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9697 - sparse_categorical_accuracy: 0.0091 - val_loss: 2.0032 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 11/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9655 - sparse_categorical_accuracy: 0.0091 - val_loss: 1.9938 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 12/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9570 - sparse_categorical_accuracy: 0.0091 - val_loss: 1.9844 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 13/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9496 - sparse_categorical_accuracy: 0.0091 - val_loss: 1.9744 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 14/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9455 - sparse_categorical_accuracy: 0.0091 - val_loss: 1.9801 - val_sparse_categorical_accuracy: 0.0089\n",
      "Epoch 15/15\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.9387 - sparse_categorical_accuracy: 0.0091 - val_loss: 1.9804 - val_sparse_categorical_accuracy: 0.0089\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "# lr - learning rate, momentum - additional parameter influencing gradient descent\n",
    "optimizer = SGD(lr=0.001, momentum = 0.9) \n",
    "#optimizer = Adadelta()\n",
    "\n",
    "inputs = keras.Input(shape=(198,)) # We give a 198 length vector\n",
    "\n",
    "dense = Dense(64, activation=\"relu\")\n",
    "x = dense(inputs)\n",
    "x = Dense(32, activation=\"elu\")(x)\n",
    "outputs = Dense(14)(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"route_grader\")\n",
    "\n",
    "# Compile the model, asking also to keep track of accuracy at different iterations\n",
    "model.compile(optimizer = optimizer, loss = 'SparseCategoricalCrossentropy', metrics = ['SparseCategoricalAccuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model. If you want to see the progress, set verbose=True (it is also True by default)\n",
    "history = model.fit(X_train, Y_train, epochs = epochs, verbose=True, shuffle=True,\n",
    "                    validation_data = (X_test,Y_test), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df784b18",
   "metadata": {},
   "source": [
    "# Continuous predictor?\n",
    "\n",
    "What if we treat out outcome variable as a continuous value? So we just want to get as close to the true grade as possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d793b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 3ms/step - loss: 1.9867 - mean_absolute_error: 1.9867 - val_loss: 1.6177 - val_mean_absolute_error: 1.6177\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.6103 - mean_absolute_error: 1.6103 - val_loss: 1.5180 - val_mean_absolute_error: 1.5180\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.5173 - mean_absolute_error: 1.5173 - val_loss: 1.4285 - val_mean_absolute_error: 1.4285\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.4261 - mean_absolute_error: 1.4261 - val_loss: 1.3423 - val_mean_absolute_error: 1.3423\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.3481 - mean_absolute_error: 1.3481 - val_loss: 1.2792 - val_mean_absolute_error: 1.2792\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.2872 - mean_absolute_error: 1.2872 - val_loss: 1.2339 - val_mean_absolute_error: 1.2339\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.2405 - mean_absolute_error: 1.2405 - val_loss: 1.1962 - val_mean_absolute_error: 1.1962\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.2028 - mean_absolute_error: 1.2028 - val_loss: 1.1645 - val_mean_absolute_error: 1.1645\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.1708 - mean_absolute_error: 1.1708 - val_loss: 1.1370 - val_mean_absolute_error: 1.1370\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.1442 - mean_absolute_error: 1.1442 - val_loss: 1.1152 - val_mean_absolute_error: 1.1152\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.1208 - mean_absolute_error: 1.1208 - val_loss: 1.0958 - val_mean_absolute_error: 1.0958\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.1002 - mean_absolute_error: 1.1002 - val_loss: 1.0777 - val_mean_absolute_error: 1.0777\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0818 - mean_absolute_error: 1.0818 - val_loss: 1.0608 - val_mean_absolute_error: 1.0608\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0655 - mean_absolute_error: 1.0655 - val_loss: 1.0483 - val_mean_absolute_error: 1.0483\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0510 - mean_absolute_error: 1.0510 - val_loss: 1.0364 - val_mean_absolute_error: 1.0364\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0377 - mean_absolute_error: 1.0377 - val_loss: 1.0262 - val_mean_absolute_error: 1.0262\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0248 - mean_absolute_error: 1.0248 - val_loss: 1.0163 - val_mean_absolute_error: 1.0163\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0130 - mean_absolute_error: 1.0130 - val_loss: 1.0087 - val_mean_absolute_error: 1.0087\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 1.0022 - mean_absolute_error: 1.0022 - val_loss: 1.0017 - val_mean_absolute_error: 1.0017\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9920 - mean_absolute_error: 0.9920 - val_loss: 0.9931 - val_mean_absolute_error: 0.9931\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9828 - mean_absolute_error: 0.9828 - val_loss: 0.9869 - val_mean_absolute_error: 0.9869\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9739 - mean_absolute_error: 0.9739 - val_loss: 0.9843 - val_mean_absolute_error: 0.9843\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9664 - mean_absolute_error: 0.9664 - val_loss: 0.9756 - val_mean_absolute_error: 0.9756\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9589 - mean_absolute_error: 0.9589 - val_loss: 0.9704 - val_mean_absolute_error: 0.9704\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9517 - mean_absolute_error: 0.9517 - val_loss: 0.9669 - val_mean_absolute_error: 0.9669\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9449 - mean_absolute_error: 0.9449 - val_loss: 0.9633 - val_mean_absolute_error: 0.9633\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9389 - mean_absolute_error: 0.9389 - val_loss: 0.9597 - val_mean_absolute_error: 0.9597\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9327 - mean_absolute_error: 0.9327 - val_loss: 0.9533 - val_mean_absolute_error: 0.9533\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9270 - mean_absolute_error: 0.9270 - val_loss: 0.9555 - val_mean_absolute_error: 0.9555\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9225 - mean_absolute_error: 0.9225 - val_loss: 0.9489 - val_mean_absolute_error: 0.9489\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9167 - mean_absolute_error: 0.9167 - val_loss: 0.9438 - val_mean_absolute_error: 0.9438\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9122 - mean_absolute_error: 0.9122 - val_loss: 0.9432 - val_mean_absolute_error: 0.9432\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.9083 - mean_absolute_error: 0.9083 - val_loss: 0.9391 - val_mean_absolute_error: 0.9391\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.9037 - mean_absolute_error: 0.9037 - val_loss: 0.9362 - val_mean_absolute_error: 0.9362\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8991 - mean_absolute_error: 0.8991 - val_loss: 0.9334 - val_mean_absolute_error: 0.9334\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8950 - mean_absolute_error: 0.8950 - val_loss: 0.9326 - val_mean_absolute_error: 0.9326\n",
      "Epoch 37/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8918 - mean_absolute_error: 0.8918 - val_loss: 0.9334 - val_mean_absolute_error: 0.9334\n",
      "Epoch 38/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8878 - mean_absolute_error: 0.8878 - val_loss: 0.9277 - val_mean_absolute_error: 0.9277\n",
      "Epoch 39/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8845 - mean_absolute_error: 0.8845 - val_loss: 0.9254 - val_mean_absolute_error: 0.9254\n",
      "Epoch 40/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8812 - mean_absolute_error: 0.8812 - val_loss: 0.9255 - val_mean_absolute_error: 0.9255\n",
      "Epoch 41/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8779 - mean_absolute_error: 0.8779 - val_loss: 0.9248 - val_mean_absolute_error: 0.9248\n",
      "Epoch 42/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8749 - mean_absolute_error: 0.8749 - val_loss: 0.9233 - val_mean_absolute_error: 0.9233\n",
      "Epoch 43/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8722 - mean_absolute_error: 0.8722 - val_loss: 0.9186 - val_mean_absolute_error: 0.9186\n",
      "Epoch 44/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8694 - mean_absolute_error: 0.8694 - val_loss: 0.9170 - val_mean_absolute_error: 0.9170\n",
      "Epoch 45/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8666 - mean_absolute_error: 0.8666 - val_loss: 0.9157 - val_mean_absolute_error: 0.9157\n",
      "Epoch 46/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8638 - mean_absolute_error: 0.8638 - val_loss: 0.9144 - val_mean_absolute_error: 0.9144\n",
      "Epoch 47/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8622 - mean_absolute_error: 0.8622 - val_loss: 0.9145 - val_mean_absolute_error: 0.9145\n",
      "Epoch 48/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8595 - mean_absolute_error: 0.8595 - val_loss: 0.9139 - val_mean_absolute_error: 0.9139\n",
      "Epoch 49/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8575 - mean_absolute_error: 0.8575 - val_loss: 0.9101 - val_mean_absolute_error: 0.9101\n",
      "Epoch 50/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8549 - mean_absolute_error: 0.8549 - val_loss: 0.9120 - val_mean_absolute_error: 0.9120\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8527 - mean_absolute_error: 0.8527 - val_loss: 0.9097 - val_mean_absolute_error: 0.9097\n",
      "Epoch 52/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8507 - mean_absolute_error: 0.8507 - val_loss: 0.9119 - val_mean_absolute_error: 0.9119\n",
      "Epoch 53/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8482 - mean_absolute_error: 0.8482 - val_loss: 0.9084 - val_mean_absolute_error: 0.9084\n",
      "Epoch 54/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8457 - mean_absolute_error: 0.8457 - val_loss: 0.9076 - val_mean_absolute_error: 0.9076\n",
      "Epoch 55/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8440 - mean_absolute_error: 0.8440 - val_loss: 0.9048 - val_mean_absolute_error: 0.9048\n",
      "Epoch 56/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8429 - mean_absolute_error: 0.8429 - val_loss: 0.9032 - val_mean_absolute_error: 0.9032\n",
      "Epoch 57/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8405 - mean_absolute_error: 0.8405 - val_loss: 0.9056 - val_mean_absolute_error: 0.9056\n",
      "Epoch 58/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8386 - mean_absolute_error: 0.8386 - val_loss: 0.9105 - val_mean_absolute_error: 0.9105\n",
      "Epoch 59/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8371 - mean_absolute_error: 0.8371 - val_loss: 0.9035 - val_mean_absolute_error: 0.9035\n",
      "Epoch 60/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8351 - mean_absolute_error: 0.8351 - val_loss: 0.9060 - val_mean_absolute_error: 0.9060\n",
      "Epoch 61/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8336 - mean_absolute_error: 0.8336 - val_loss: 0.9007 - val_mean_absolute_error: 0.9007\n",
      "Epoch 62/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8319 - mean_absolute_error: 0.8319 - val_loss: 0.9046 - val_mean_absolute_error: 0.9046\n",
      "Epoch 63/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8302 - mean_absolute_error: 0.8302 - val_loss: 0.9021 - val_mean_absolute_error: 0.9021\n",
      "Epoch 64/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8286 - mean_absolute_error: 0.8286 - val_loss: 0.9009 - val_mean_absolute_error: 0.9009\n",
      "Epoch 65/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8266 - mean_absolute_error: 0.8266 - val_loss: 0.9022 - val_mean_absolute_error: 0.9022\n",
      "Epoch 66/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8251 - mean_absolute_error: 0.8251 - val_loss: 0.8965 - val_mean_absolute_error: 0.8965\n",
      "Epoch 67/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8235 - mean_absolute_error: 0.8235 - val_loss: 0.8974 - val_mean_absolute_error: 0.8974\n",
      "Epoch 68/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8223 - mean_absolute_error: 0.8223 - val_loss: 0.8984 - val_mean_absolute_error: 0.8984\n",
      "Epoch 69/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8209 - mean_absolute_error: 0.8209 - val_loss: 0.8966 - val_mean_absolute_error: 0.8966\n",
      "Epoch 70/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8199 - mean_absolute_error: 0.8199 - val_loss: 0.8963 - val_mean_absolute_error: 0.8963\n",
      "Epoch 71/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8175 - mean_absolute_error: 0.8175 - val_loss: 0.8932 - val_mean_absolute_error: 0.8932\n",
      "Epoch 72/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8161 - mean_absolute_error: 0.8161 - val_loss: 0.8942 - val_mean_absolute_error: 0.8942\n",
      "Epoch 73/100\n",
      "74/74 [==============================] - 0s 2ms/step - loss: 0.8142 - mean_absolute_error: 0.8142 - val_loss: 0.8925 - val_mean_absolute_error: 0.8925\n",
      "Epoch 74/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8137 - mean_absolute_error: 0.8137 - val_loss: 0.8931 - val_mean_absolute_error: 0.8931\n",
      "Epoch 75/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8115 - mean_absolute_error: 0.8115 - val_loss: 0.8943 - val_mean_absolute_error: 0.8943\n",
      "Epoch 76/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8096 - mean_absolute_error: 0.8096 - val_loss: 0.8933 - val_mean_absolute_error: 0.8933\n",
      "Epoch 77/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8085 - mean_absolute_error: 0.8085 - val_loss: 0.8903 - val_mean_absolute_error: 0.8903\n",
      "Epoch 78/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8068 - mean_absolute_error: 0.8068 - val_loss: 0.8907 - val_mean_absolute_error: 0.8907\n",
      "Epoch 79/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8053 - mean_absolute_error: 0.8053 - val_loss: 0.8892 - val_mean_absolute_error: 0.8892\n",
      "Epoch 80/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8041 - mean_absolute_error: 0.8041 - val_loss: 0.8916 - val_mean_absolute_error: 0.8916\n",
      "Epoch 81/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8024 - mean_absolute_error: 0.8024 - val_loss: 0.8890 - val_mean_absolute_error: 0.8890\n",
      "Epoch 82/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.8013 - mean_absolute_error: 0.8013 - val_loss: 0.8901 - val_mean_absolute_error: 0.8901\n",
      "Epoch 83/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7991 - mean_absolute_error: 0.7991 - val_loss: 0.8938 - val_mean_absolute_error: 0.8938\n",
      "Epoch 84/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7975 - mean_absolute_error: 0.7975 - val_loss: 0.8885 - val_mean_absolute_error: 0.8885\n",
      "Epoch 85/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7963 - mean_absolute_error: 0.7963 - val_loss: 0.8880 - val_mean_absolute_error: 0.8880\n",
      "Epoch 86/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7949 - mean_absolute_error: 0.7949 - val_loss: 0.8872 - val_mean_absolute_error: 0.8872\n",
      "Epoch 87/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7935 - mean_absolute_error: 0.7935 - val_loss: 0.8864 - val_mean_absolute_error: 0.8864\n",
      "Epoch 88/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7920 - mean_absolute_error: 0.7920 - val_loss: 0.8860 - val_mean_absolute_error: 0.8860\n",
      "Epoch 89/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7910 - mean_absolute_error: 0.7910 - val_loss: 0.8871 - val_mean_absolute_error: 0.8871\n",
      "Epoch 90/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7885 - mean_absolute_error: 0.7885 - val_loss: 0.8855 - val_mean_absolute_error: 0.8855\n",
      "Epoch 91/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7873 - mean_absolute_error: 0.7873 - val_loss: 0.8868 - val_mean_absolute_error: 0.8868\n",
      "Epoch 92/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7863 - mean_absolute_error: 0.7863 - val_loss: 0.8888 - val_mean_absolute_error: 0.8888\n",
      "Epoch 93/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7842 - mean_absolute_error: 0.7842 - val_loss: 0.8834 - val_mean_absolute_error: 0.8834\n",
      "Epoch 94/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7832 - mean_absolute_error: 0.7832 - val_loss: 0.8869 - val_mean_absolute_error: 0.8869\n",
      "Epoch 95/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7812 - mean_absolute_error: 0.7812 - val_loss: 0.8856 - val_mean_absolute_error: 0.8856\n",
      "Epoch 96/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7798 - mean_absolute_error: 0.7798 - val_loss: 0.8886 - val_mean_absolute_error: 0.8886\n",
      "Epoch 97/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7781 - mean_absolute_error: 0.7781 - val_loss: 0.8869 - val_mean_absolute_error: 0.8869\n",
      "Epoch 98/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7767 - mean_absolute_error: 0.7767 - val_loss: 0.8853 - val_mean_absolute_error: 0.8853\n",
      "Epoch 99/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7757 - mean_absolute_error: 0.7757 - val_loss: 0.8874 - val_mean_absolute_error: 0.8874\n",
      "Epoch 100/100\n",
      "74/74 [==============================] - 0s 1ms/step - loss: 0.7733 - mean_absolute_error: 0.7733 - val_loss: 0.8874 - val_mean_absolute_error: 0.8874\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 128\n",
    "# lr - learning rate, momentum - additional parameter influencing gradient descent\n",
    "coptimizer = SGD(lr=0.001, momentum = 0.9) \n",
    "#optimizer = Adadelta()\n",
    "\n",
    "cinputs = keras.Input(shape=(198,)) # We give a 198 length vector\n",
    "\n",
    "cdense = Dense(64, activation=\"relu\")\n",
    "cx = dense(inputs)\n",
    "cx = Dense(32, activation=\"elu\")(cx)\n",
    "coutputs = Dense(1)(cx)\n",
    "c_model = keras.Model(inputs=cinputs, outputs=coutputs, name=\"route_grader\")\n",
    "\n",
    "# Compile the model, asking also to keep track of accuracy at different iterations\n",
    "c_model.compile(optimizer = coptimizer, loss = 'mean_absolute_error', metrics = ['mean_absolute_error'])\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model. If you want to see the progress, set verbose=True (it is also True by default)\n",
    "c_history = c_model.fit(X_train, Y_train, epochs = epochs, verbose=True, shuffle=True,\n",
    "                    validation_data = (X_test,Y_test), batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d09dad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c_model.predict(X_test, batch_size = len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7c810d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absGradeMetric(y_true, y_pred):\n",
    "    close = 1\n",
    "    y_pred = tf.cast(y_pred, tf.float32) # Some categorical number (we use one-hot encoding)\n",
    "    y_true = tf.cast(y_true, tf.float32) # Another categorical\n",
    "    cur_acc = 0\n",
    "    cur_acc = tf.cast(cur_acc, tf.float32)\n",
    "    temp = 0\n",
    "    div = tf.cast(len(y_pred), tf.float32)\n",
    "    for t in range(len(y_pred)):\n",
    "        temp = tf.math.subtract(y_true[t], y_pred[t])\n",
    "        temp = tf.math.abs(temp)\n",
    "        temp = tf.math.less_equal(temp, [close])\n",
    "        temp = tf.math.count_nonzero(temp)\n",
    "        temp = tf.cast(temp, tf.float32)\n",
    "        cur_acc = tf.math.add(cur_acc, temp)\n",
    "    return tf.math.divide(cur_acc, div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6189f1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.66200763>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = absGradeMetric(Y_test, c)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e261573",
   "metadata": {},
   "source": [
    "This is pretty good! We're within 1 of our desired grade 66% of the time! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab8a8a",
   "metadata": {},
   "source": [
    "# Adding in a Softmax (binary classification) layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54359248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\isaac\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "batch_size = 128\n",
    "# lr - learning rate, momentum - additional parameter influencing gradient descent\n",
    "optimizer = SGD(lr=0.0001, momentum = 0.9) \n",
    "#optimizer = Adadelta()\n",
    "\n",
    "sinputs = keras.Input(shape=(198,)) # We give a 198 length vector\n",
    "\n",
    "sdense = Dense(64, activation=\"relu\")\n",
    "sx = dense(sinputs)\n",
    "sx = Dense(32, activation=\"elu\")(sx)\n",
    "soutputs = Softmax()(sx)\n",
    "s_model = keras.Model(inputs=sinputs, outputs=soutputs, name=\"route_grader\")\n",
    "\n",
    "# Compile the model, asking also to keep track of accuracy at different iterations\n",
    "s_model.compile(optimizer = optimizer, loss = 'SparseCategoricalCrossentropy', metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(k=2)])\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model. If you want to see the progress, set verbose=True (it is also True by default)\n",
    "s_history = s_model.fit(X_train, Y_train, epochs = epochs, verbose=False, shuffle=True,\n",
    "                    validation_data = (X_test,Y_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "336a7895",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00449764, 0.16607796, 0.18315545, 0.14609867, 0.14578971,\n",
       "       0.10127249, 0.06750966, 0.03809708, 0.01823396, 0.00503782,\n",
       "       0.00778396, 0.00463027, 0.00514949, 0.00661064, 0.00636872,\n",
       "       0.00434186, 0.00551474, 0.00600892, 0.00579597, 0.00689028,\n",
       "       0.00473902, 0.00535985, 0.00580101, 0.00617219, 0.00601625,\n",
       "       0.00563837, 0.00474754, 0.00586095, 0.00570688, 0.00621067,\n",
       "       0.00426132, 0.00462066], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf = s_model.predict(X_test, batch_size = len(X_test))\n",
    "sf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7660d549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 19005 calls to <function Model.make_test_function.<locals>.test_function at 0x00000147C1109280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 1.3162 - sparse_top_k_categorical_accuracy: 0.6811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3162411451339722, 0.6810673475265503]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model.compile(optimizer = optimizer, loss = 'SparseCategoricalCrossentropy', metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(k=2)])\n",
    "s_model.evaluate(X_test,Y_test, batch_size = len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6cb2ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_model.compile(optimizer = optimizer, loss = 'SparseCategoricalCrossentropy', metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a7d23e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step - loss: 1.3162 - sparse_top_k_categorical_accuracy: 0.8217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3162411451339722, 0.8216857314109802]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_model.evaluate(X_test,Y_test, batch_size = len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d16bac",
   "metadata": {},
   "source": [
    "So our model will find the true grade of climbing routes within the top 3 guesses 82% of the time! And within the top two 70% of the time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0941d99",
   "metadata": {},
   "source": [
    "# Making The Grade\n",
    "\n",
    "The 6A-8C scale is a little wide for my tastes. Let's try condensing the grades, and retesting our initial models to see if that helps. We'll go from 14 classes to either 9 or 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "b498dfaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6B',\n",
       " '6B+',\n",
       " '6C',\n",
       " '6C+',\n",
       " '7A',\n",
       " '7A+',\n",
       " '7B',\n",
       " '7B+',\n",
       " '7C',\n",
       " '7C+',\n",
       " '8A',\n",
       " '8A+',\n",
       " '8B',\n",
       " '8B+']"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d2d49379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6B\n",
      "1 6B+\n",
      "2 6C\n",
      "3 6C+\n",
      "4 7A\n",
      "5 7A+\n",
      "6 7B\n",
      "7 7B+\n",
      "8 7C\n",
      "9 7C+\n",
      "10 8A\n",
      "11 8A+\n",
      "12 8B\n",
      "13 8B+\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rep_arr)):\n",
    "    print(rep_arr[i], grades[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "c9d4a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.replace(rep_arr, [0, 0,1,1,2,3,4,4,5,6,7,8,9,10], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "5a820419",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test, w_train, w_test = train_test_split(X, Y, weights, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8824351b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 128\n",
    "# lr - learning rate, momentum - additional parameter influencing gradient descent\n",
    "optimizer = SGD(lr=0.0001, momentum = 0.9) \n",
    "#optimizer = Adadelta()\n",
    "\n",
    "gsinputs = keras.Input(shape=(198,)) # We give a 198 length vector\n",
    "\n",
    "gsdense = Dense(64, activation=\"relu\")\n",
    "gsx = dense(gsinputs)\n",
    "gsx = Dense(32, activation=\"elu\")(gsx)\n",
    "gsoutputs = Softmax()(gsx)\n",
    "gs_model = keras.Model(inputs=gsinputs, outputs=gsoutputs, name=\"route_grader\")\n",
    "\n",
    "# Compile the model, asking also to keep track of accuracy at different iterations\n",
    "gs_model.compile(optimizer = optimizer, loss = 'SparseCategoricalCrossentropy', metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(k=2)])\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model. If you want to see the progress, set verbose=True (it is also True by default)\n",
    "gs_history = gs_model.fit(X_train, Y_train, epochs = epochs, verbose=False, shuffle=True,\n",
    "                    validation_data = (X_test,Y_test), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b2a0d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step - loss: 1.3595 - sparse_top_k_categorical_accuracy: 0.6662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3594778776168823, 0.6662431359291077]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.evaluate(X_test,Y_test, batch_size = len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956d2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
